{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget -q https://omnomnom.vision.rwth-aachen.de/data/metrabs/metrabs_multiperson_smpl_combined.zip -P models\n",
    "# ! unzip -q 'models/*.zip' -d models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to load model : 16.876500129699707\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    t1 = time.time()\n",
    "    model = tf.saved_model.load('models/metrabs_multiperson_smpl_combined')\n",
    "    t2 = time.time()\n",
    "    print('Total time to load model :', (t2-t1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path='vera.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_predict(data_path):\n",
    "    det=[]\n",
    "    pose_3d=[]\n",
    "    pose_2d=[]\n",
    "    frames=[]\n",
    "    joints=[]\n",
    "    cap = cv2.VideoCapture(data_path)\n",
    "    while True:\n",
    "        flag, frame = cap.read()\n",
    "        height, width = frame.shape[:2]\n",
    "        if height < width:\n",
    "              frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE) \n",
    "        frame = tf.convert_to_tensor(frame)\n",
    "        with tf.device('/device:GPU:0'):\n",
    "            detections, poses3d, poses2d = model.predict_single_image(frame)\n",
    "            det.append(detections)\n",
    "            pose_3d.append(poses3d)\n",
    "            pose_2d.append(poses2d)\n",
    "            frames.append(frame)\n",
    "            joints.append(model.joint_edges.numpy())\n",
    "        \n",
    "        if flag:\n",
    "        # The frame is ready and already captured\n",
    "            pos_frame = cap.get(cv2.CAP_PROP_POS_FRAMES)\n",
    "            #print(str(pos_frame)+\" frames\")\n",
    "            cv2.destroyAllWindows()\n",
    "        else:\n",
    "        # The next frame is not ready, so we try to read it again\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, pos_frame-1)\n",
    "            print( \"frame is not ready\")\n",
    "        # It is better to wait for a while for the next frame to be ready\n",
    "            cv2.waitKey(1000)\n",
    "        if cv2.waitKey(10) == 27:\n",
    "            break\n",
    "        if cap.get(cv2.CAP_PROP_POS_FRAMES) == cap.get(cv2.CAP_PROP_FRAME_COUNT):\n",
    "        # If the number of captured frames is equal to the total number of frames,\n",
    "        # we stop\n",
    "            break\n",
    "    return frames, det, pose_3d, pose_2d, joints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time to get predictions : 33.442110538482666\n"
     ]
    }
   ],
   "source": [
    "t1 = time.time()\n",
    "frames, det, pose_3d, pose_2d, joints = video_predict(data_path)\n",
    "t2 = time.time()\n",
    "print('Total time to get predictions :', (t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#тут только нужные точки\n",
    "import numpy as np\n",
    "poses3d=[]\n",
    "idx = [14,15,16, 17, 18, 19, 20, 0,1,3,4,6,7,9,10,21,22,23,2]\n",
    "for pose in pose_3d:\n",
    "    poses3d.append(pose.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import IntEnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Keypoints(IntEnum):\n",
    "    Head = 0\n",
    "    LShoulder = 1\n",
    "    RShoulder  = 2\n",
    "    LElbow = 3\n",
    "    RElbow = 4\n",
    "    LWrist = 5\n",
    "    RWrist = 6 \n",
    "    LHip = 7\n",
    "    RHip = 8\n",
    "    LKnee = 9\n",
    "    RKnee = 10\n",
    "    LAnkle = 11 \n",
    "    RAnkle = 12\n",
    "    LToe = 13\n",
    "    RToe = 14\n",
    "    LHan = 15\n",
    "    RHan = 16\n",
    "    Pelv = 17\n",
    "    Bell = 18\n",
    "#     ClubFace = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def writer(poses3d,data_path):\n",
    "    csv_path='csv_dir'\n",
    "    file=data_path.split(\".\")[0]+'.csv'\n",
    "\n",
    "    try:\n",
    "        if not os.path.exists(csv_path):\n",
    "            os.mkdir(csv_path)\n",
    "    except Exception as e:\n",
    "        print(repr(e))\n",
    "        raise e\n",
    "        \n",
    "    with open('csv_dir/{}'.format(file), mode='w') as csv_file:\n",
    "        csv_writer = csv.writer(csv_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "        csv_writer.writerow(['frame_no',\n",
    "                         'Head.x', 'Head.y', 'Head.z'\n",
    "                         'LShoulder.x', ' LShoulder.y', ' LShoulder.z',\n",
    "                         'RShoulder.x', 'RShoulder.y', 'RShoulder.z',\n",
    "                         'LElbow.x', 'LElbow.y', 'LElbow.z',\n",
    "                         'RElbow.x', 'RElbow.y', 'RElbow.z',\n",
    "                         'LWrist.x', 'LWrist.y', 'LWrist.z',\n",
    "                         'RWrist.x', 'RWrist.y', 'RWrist.z',\n",
    "                         'LHip.x', 'LHip.y', 'LHip.z',\n",
    "                         'RHip.x', 'RHip.y', 'RHip.z',\n",
    "                         'LKnee.x', 'LKnee.y', 'LKnee.z',\n",
    "                         'RKnee.x', 'RKnee.y', 'RKnee.z',\n",
    "                         'LAnkle.x', 'LAnkle.y', 'LAnkle.z',\n",
    "                         'RAnkle.x', 'RAnkle.y', 'RAnkle.z',\n",
    "                         'LToe.x', 'LToe.y', 'LToe.z',\n",
    "                         'RToe.x', 'RToe.y', 'RToe.z',\n",
    "                         'LHan.x', 'LHan.y', 'LHan.z',\n",
    "                         'RHan.x', 'RHan.y', 'RHan.z',\n",
    "                         'Pelv.x', 'Pelv.y', 'Pelv.z',\n",
    "                         'Bell.x', 'Bell.y', 'Bell.z'\n",
    "#                          'spin.x', 'spin.y', 'spin.z',\n",
    "#                          'thor.x', 'thor.y', 'thor.z',\n",
    "#                          'neck.x', 'neck.y', 'neck.z',\n",
    "#                          'lcla.x', 'lcla.y', 'lcla.z',\n",
    "#                          'rcla.x', 'rcla.y', 'rcla.z',\n",
    "#                          'ClubFace.x', 'ClubFace.y', 'ClubFace.z'\n",
    "                         ])\n",
    "        \n",
    "        for frame, pose in enumerate(poses3d):\n",
    "            row = [frame] + ['' for _ in range(57)]  # Не забыть поправить когда добавлю клюшку Number of coco points * 3 -> 19 * 3 -> 57\n",
    "            p=pose[0]\n",
    "            for part in Keypoints:\n",
    "                index = 1 + 3 * part.value  # Index at which the values for this joint would start in the final row\n",
    "                row[index] = p[part.value][0]\n",
    "                row[index + 1] = p[part.value][1] \n",
    "                row[index + 2] = p[part.value][2]\n",
    "            csv_writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer(poses3d,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(path):\n",
    "    \"\"\"Load keypoint coordinates stored in a CSV file.\n",
    "    Columns are in order frame_no, nose.(x|y|p), (l|r)eye.(x|y|p), (l|r)ear.(x|y|p), (l|r)shoulder.(x|y|p),\n",
    "    (l|r)elbow.(x|y|p), (l|r)wrist.(x|y|p), (l|r)hip.(x|y|p), (l|r)knee.(x|y|p), (l|r)ankle.(x|y|p)\n",
    "    l - Left side of the identified joint\n",
    "    r - Right side of the identified joint\n",
    "    x - X coordinate of the identified joint\n",
    "    y - Y coordinate of the identified joint\n",
    "    p - Probability of the identified joint\n",
    "    Coordinate list for a frame = [ [x, y], [x, y], [x, y], ... ]\n",
    "    *coordinates in order specified in the CSV header\n",
    "    Returns a list of coordinates for each frame = [ [...], [...], ... ]\n",
    "    :param csv_fp: Path to the CSV file\n",
    "    \"\"\"\n",
    "    import csv\n",
    "    \n",
    "    pose_coordinates = []\n",
    "\n",
    "    with open(path, 'r') as csv_file:\n",
    "        reader = csv.reader(csv_file, delimiter=',')\n",
    "        next(reader)\n",
    "\n",
    "        for row in reader:\n",
    "            # TODO: Figure out a way to handle missing joints\n",
    "            coordinates = []  # List to store XY coordinates of every joint\n",
    "\n",
    "            # Fill up the coordinate list for a single frame\n",
    "            for index in range(1, len(row), 3):  # Starting from 1 to skip frame column, 3 because joint.x|y|prob\n",
    "                coordinates.append([float(row[index]), float(row[index + 1]),float(row[index + 2])])\n",
    "\n",
    "            # Fill up the final list with coordinate lists of all the frames\n",
    "            pose_coordinates.append(coordinates)\n",
    "\n",
    "    return pose_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_coordinates=load_csv('csv_dir/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(all_coordinates):\n",
    "    \"\"\"The normalization is a simple coordinate transformation done in two steps:\n",
    "    1. Translation: All the key points are translated such that the nose key point becomes the origin of the coordinate\n",
    "        system. This is achieved by subtracting the nose key points coordinates from all other key points.\n",
    "    2. Scaling: The key points are scaled such that the distance between the left shoulder and right shoulder key point\n",
    "        becomes 1. This is done by dividing all key points coordinates by the distance between the left and right\n",
    "        shoulder key point.\n",
    "    \"\"\"\n",
    "    \n",
    "    import math\n",
    "    import numpy\n",
    "    \n",
    "    from math import sqrt\n",
    "    \n",
    "    norm_coords = []  # Hold the normalised coordinates for every frame\n",
    "\n",
    "    # Iterate over every frame\n",
    "    for coordinates in all_coordinates:\n",
    "        # Step 1: Translate\n",
    "        \n",
    "        coordinates = [\n",
    "            [coordinate[0] - coordinates[Keypoints.Head.value][0], coordinate[1] - coordinates[Keypoints.Head.value][1],coordinate[2] - coordinates[Keypoints.Head.value][2]]\n",
    "            for coordinate in coordinates\n",
    "        ]\n",
    "        \n",
    "        # Step 2: Scale\n",
    "        x= coordinates[Keypoints.LShoulder.value][0] - coordinates[Keypoints.RShoulder.value][0]\n",
    "        y= coordinates[Keypoints.LShoulder.value][1] - coordinates[Keypoints.RShoulder.value][1]\n",
    "        z= coordinates[Keypoints.LShoulder.value][2] - coordinates[Keypoints.RShoulder.value][2]\n",
    "        dist=sqrt(x*x+y*y+z*z)\n",
    "#         dist = math.hypot(coordinates[Keypoints.LShoulder.value][0] - coordinates[Keypoints.RShoulder.value][0],\n",
    "#                           coordinates[Keypoints.LShoulder.value][1] - coordinates[Keypoints.RShoulder.value][1],\n",
    "#                           coordinates[Keypoints.LShoulder.value][2] - coordinates[Keypoints.RShoulder.value][2])\n",
    "#         print(dist)\n",
    "        coordinates = [[coordinate[0] / dist, coordinate[1] / dist, coordinate[2] / dist] for coordinate in coordinates]\n",
    "\n",
    "        norm_coords.append(coordinates)\n",
    "\n",
    "    return norm_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n=normalise(all_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math\n",
    "import sys\n",
    "from itertools import chain\n",
    "# from typing import List\n",
    "\n",
    "import fastdtw\n",
    "import numpy as np\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "from scipy.signal import medfilt\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "\n",
    "def calculate_score(seq1, seq2, dimensions):\n",
    "    \"\"\"Calculate how similar the two pose sequences are.\"\"\"\n",
    "\n",
    "    def process_signal(signal):\n",
    "        \"\"\"Final processing before dynamic time warping.\"\"\"\n",
    "        # Apply Gaussian filter for further processing\n",
    "        signal = gaussian_filter(signal, sigma=1)\n",
    "\n",
    "        # Make the sequence/signal zero-mean by subtracting the mean from it\n",
    "        mean = np.mean(signal)\n",
    "        return [x - mean for x in signal]\n",
    "\n",
    "    distance = 0.0\n",
    "\n",
    "    for dim in dimensions:\n",
    "        sig1 = process_signal(signal=seq1[dim])\n",
    "        sig2 = process_signal(signal=seq2[dim])\n",
    "\n",
    "        temp_distance, _ = fastdtw.fastdtw(sig1, sig2, radius=30, dist=euclidean)\n",
    "        distance += temp_distance\n",
    "\n",
    "    # Normalise DTW score\n",
    "    distance /= len(dimensions)\n",
    "\n",
    "    return distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dimension_selection(frames):\n",
    "    \"\"\"Remove indices that don't vary a lot during the pose.\n",
    "    Key points that do not move significantly in the sequence will cause the signals of the respective coordinates to be\n",
    "    roughly constant with only little variance. All signals whose variance is below a threshold will be filtered out and\n",
    "    are assumed to be uninformative.\n",
    "    :returns: A set of indices of dimensions that should be kept\n",
    "    \"\"\"\n",
    "\n",
    "#     def keep_sequence(seq: List) -> bool:\n",
    "#         \"\"\"Check whether the points in the sequence vary a lot or not.\"\"\"\n",
    "#         # Use a median filter for smoothing\n",
    "#         seq = medfilt(seq, kernel_size=3)\n",
    "\n",
    "#         # Filter the dimension based on variance\n",
    "#         return np.var(seq) > 0.10\n",
    "\n",
    "    # Reorder the coordinates such that they are per joint and not per frame\n",
    "    frames = [list(chain(*frame)) for frame in frames]  # Flatten the nested lists inside\n",
    "    sequences = list(map(list, zip(*frames)))  # Transpose the list\n",
    "\n",
    "    # Drop low variance columns\n",
    "    dimensions = [i for i, sequence in enumerate(sequences)]\n",
    "\n",
    "    return dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(path_1,path_2):    \n",
    "    \n",
    "    pose_csv1 = path_1\n",
    "    pose_csv2 = path_2\n",
    "\n",
    "    # Load the CSVs\n",
    "    pose1 = load_csv(path=pose_csv1)\n",
    "    pose2 = load_csv(path=pose_csv2)\n",
    "\n",
    "    # Normalization\n",
    "    pose1 = normalise(pose1)\n",
    "    pose2 = normalise(pose2)\n",
    "\n",
    "    # # Dimension Selection\n",
    "    pose1_dimensions = dimension_selection(pose1.copy())\n",
    "    pose2_dimensions = dimension_selection(pose2.copy())\n",
    "#     print(pose1 + pose2)\n",
    "    dimensions = sorted(set(pose1_dimensions + pose2_dimensions))  # Take a union to get final list of dimensions\n",
    "\n",
    "    score = calculate_score(pose1, pose2, dimensions)\n",
    "    print(f'Score = {score:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score = 0.000000\n"
     ]
    }
   ],
   "source": [
    "score=main('csv_dir/test.csv','csv_dir/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "golf_tf_2",
   "language": "python",
   "name": "golf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
